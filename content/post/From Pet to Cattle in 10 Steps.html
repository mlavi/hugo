<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
    <title>From Pet to Cattle in 10 Steps</title>
  </head>
  <body>
    <h1>From Pet to Cattle in X Steps</h1>
    40 mins presentation, 10 min Q&amp;A, review and Call to Action:
    last words linger<br>
    <br>
    <h2>Overview</h2>
    <p>We will take you on a journey of a system administrator,
      responsible for the organization's e-commerce web site, across
      various era IT best practices:</p>
    <ol>
      <li>bare-metal in the data center to...</li>
      <li>configuration management of VMs (circa 2010?) to...</li>
      <li>continually deployed infrastructure container artifacts. </li>
    </ol>
    <h2>Definitions</h2>
    <ul>
      <li>pet: SPoF with emotional attachments; hand crafted and bespoke</li>
      <li>cattle: a fleet of resources, numbered and maintained by an
        aggregate SLA</li>
      <li>DB: DataBase</li>
      <li>ETA: estimated time of arrival</li>
      <li>MTTR: mean time to restore</li>
      <li>MTTF: mean time to fix (repair)</li>
      <li>OS: Operating System</li>
      <li>www: world wide web</li>
    </ul>
    <h2>X Steps</h2>
    <ol>
      <li>The monolith in production</li>
      <ul>
        <li>full stack on one server:</li>
        <ul>
          <li>1 OS, 1 www, 1 DB</li>
          <li>config*3+data+docroot</li>
        </ul>
        <li>ops: manual</li>
        <ol>
          <li>build: OS+www+DB+config*3+docroot+data</li>
          <ul>
            <li>MTTB: sequential</li>
            <li>ETA: 8 hours</li>
          </ul>
          <li>lifecycle update stack: OS, www, DB</li>
          <ul>
            <li>downtime required potentially during each operation</li>
            <li>ETA: 2 hours</li>
          </ul>
          <li>lifecycle update config*3, data update, docroot update</li>
          <ul>
            <li>minimal downtime</li>
            <li>ETA: 0.5 hour</li>
          </ul>
          <li>maintenance backup:</li>
          <ul>
            <li>internal (on system)</li>
            <li>ETA: 1 hour</li>
            <li>external (off system)</li>
            <li>ETA: 4 hours</li>
          </ul>
          <li>failure revert change/disaster recovery:</li>
          <ul>
            <li>restore from backup = downtime</li>
            <li>MTTR ETA: 4 hours (op+checks)</li>
          </ul>
        </ol>
        <li>security:</li>
        <ul>
          <li>minimal (unless configured, OS/server/app defaults)</li>
          <li>firewall: admin+www+DB ports open</li>
        </ul>
        <li>criticism: pet infrastructure, pet architecture, pet ops</li>
        <ul>
          <li>Slow: sequential progress to install entire stack</li>
          <li>SPoF infra, arch, and probably ops</li>
          <ul>
            <li>all capacity combined (OS+DB+www+ops), cannot be
              isolated</li>
            <li>scale up possible, but no scale out</li>
            <li>no redundancy = MTTR from backup</li>
            <li>no change control plan, no safety net</li>
          </ul>
          <li>minimal security</li>
          <ul>
            <li>SPoF for DoS attacks</li>
            <li>high risk, easy to attack</li>
            <li>no defense in depth or isolation (of DB)</li>
          </ul>
          <li>no testing/monitoring/automation:</li>
          <ul>
            <li>failure must be noticed to invoke forensics and MTTF
              before revert ops, increasing MTTR </li>
            <li>best one can hope for is a run book troubleshooting
              procedure on the wiki + vendor documentation + software
              developer dox</li>
            <li>MTTR increase if backups untested: if a backup fails,
              best one can hope for is a run book troubleshooting
              procedure on the wiki + vendor documentation + software
              developer dox</li>
            <li>backup queue limited by monolith capacity</li>
            <li>backup limited to userspace copies+exports (in channel
              resource impact), also SPoF -- this prevents full image
              restoral, therefore must be composed of OS backups
              (restore points?) + restore config+data</li>
          </ul>
        </ul>
        <li><b>Question:</b> where would you go from here? [hold] who
          would vote for infrastructure separation in prod and who would
          vote for adding staging infrastructure?</li>
      </ul>
      <li>Separate monoliths: www+DB</li>
      <ul>
        <li>full stack * 2: OS+www, OS+DB </li>
        <li>security: remove firewall rules to protect only www, only
          protects DB</li>
        <li>benefit:</li>
        <ul>
          <li>distributed SPoF means that any failure operation will not
            require working on the other monolith, small reduction to
            MTTF and MTTR</li>
          <li>increased security for DB</li>
          <li>independent scale up = better capacity management option</li>
        </ul>
        <li>criticism:</li>
        <ul>
          <li>any failure still impacts the overall app downtime</li>
          <li>no scale out (yet), but we've build the first step on that
            journey</li>
          <li>operation load:</li>
          <ul>
            <li>nearly doubles, reducing work availability</li>
            <li>network + security config is a new skill set, might be a
              new team?</li>
          </ul>
        </ul>
      </ul>
      <li>Add staging monolith</li>
      <ul>
        <li>full stack * 4</li>
        <li>ops: manual, with the addition of:</li>
        <ol start="6">
          <li>sync data from prod to staging</li>
        </ol>
        <ul>
          <ul>
            <li>ETA: 2 hours</li>
          </ul>
        </ul>
        <li>security: minimal, unless staging is isolated from
          production and public traffic</li>
        <li>benefit:</li>
        <ul>
          <li>update operations can be tested in staging by hand = less
            impact/risk/downtime to production = higher uptime</li>
          <li>fallback to revert change/disaster recovery possible to
            reduce MTTR</li>
          <ul>
            <li>in a pinch, staging can be considered a redundant,
              fallback monolith, given that staging can be made public
              and change to production configuration (still manual). but
              still carry a heavy resource penalty to revert</li>
          </ul>
        </ul>
        <li>criticism</li>
        <ul>
          <li>Same as above, but now operation ETAs double</li>
          <ul>
            <li>e.g.: reproduce update from staging to prod</li>
          </ul>
          <li> still pet infrastructure, pet architecture, pet ops</li>
          <li>security minimal!</li>
          <li>limited</li>
        </ul>
      </ul>
      <li>REFACTOR INFRASTRUCTURE for speed: bare metal to VMs + cloud?
      </li>
      <li>REFACTOR INFRA+ARCH for automation: rounds</li>
      <ol>
        <li>monitors = testing, round 1</li>
        <li>Add revision contol:</li>
        <ol>
          <li>scripting builds, ops (opex cost to develop)</li>
          <li>configuration management (vs. package management = apt-get
            install wordpress, chocolatey?)</li>
          <li>Add PC EC automation: Calm blueprint = delegate,
            self-service, Infrastructure as Code</li>
        </ol>
      </ol>
      <li>BUILD + REFACTOR</li>
      <ol>
        <li>Add build system:</li>
        <ol>
          <li>build and distribute as container</li>
          <li>test as container</li>
        </ol>
      </ol>
      <li>Mono*1 &gt; +IsoMono*2*1 &gt; +DevIsoMono*2*2 &gt;
        +LBDevIsoMono*3*2 &gt; blueprintDevIsoMonoPets: cattle ops;
        that's great, but how good are your backups?</li>
      <li>blueprintSynth:scripting+orch,+RCS=IaC=Cattle infra</li>
      <li>blueprintSynth:CM=less code</li>
      <li>CI job:build infra artifacts, refactor blueprint to deploy
        them</li>
      <li>CI job:build infra artifacts, deploy them via blueprint,
        simple deploy test action exercising whole=app integration
        testing to pass commit</li>
      <li>Code review on commit: automated test harness inventory</li>
      <li>TDD/BDD IoC with blueprints</li>
      <ol>
        <li>brownfield import pets +LB in blueprint: RBAC cattle ops
          (ops as code) +audits, e.g.: 3 pets for webtier</li>
        <ol>
          <li>alice.prod.example.org</li>
          <li>betty.prod.example.org</li>
          <li>carol.prod.example.org</li>
        </ol>
        <li>synthesize pets with CM in blueprint: cattle infra as code,
          e.g.: 3 cattle of webtier in two clouds/DCs</li>
        <ol>
          <li>pet datacenter 1:</li>
        </ol>
        <ol>
          <li>www1.dc1.prod.example.org</li>
          <li>www2.dc1.prod.example.org</li>
          <li>www3.dc1.prod.example.org</li>
        </ol>
        <ol>
          <li>pet cloud datacenter 2:</li>
        </ol>
        <ol>
          <li>www1.dc2.prod.example.org</li>
          <li>www2.dc2.prod.example.org</li>
          <li>www3.dc2.prod.example.org</li>
        </ol>
        <li>refactor to cattle infra as code behind LB, tie to event
          triggers: no ops</li>
      </ol>
    </ol>
  </body>
</html>
